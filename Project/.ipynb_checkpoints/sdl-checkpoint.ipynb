{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6aed57-f0d2-4b47-ba9b-2e8bacaacceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU can be used.\n",
      "Version:  11.7\n",
      "Number of GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU can be used.\")\n",
    "    print(\"Version: \", torch.version.cuda)\n",
    "    print(\"Number of GPUs available: \", torch.cuda.device_count())\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b2f374-6c6e-48dd-bf30-d1099a3841fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pyspark.sql.functions import when, rand\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f2a915-cfe1-476b-b803-f601943fa87d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jdu5sq/spark-3.4.1-bin-hadoop3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "import findspark as fs\n",
    "fs.init('/home/jdu5sq/spark-3.4.1-bin-hadoop3')\n",
    "fs.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b4d199-0a58-4c66-aed2-1858a52793f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/jdu5sq/Documents/MSDS/DS5110/Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee63bb25-5aa8-4e9f-b480-97fe34883a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/12 05:19:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/12 05:19:45 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-an28-1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[10]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GPU Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc2ead05150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def start_spark_session():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"GPU Spark NLP\") \\\n",
    "        .master(\"local[10]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.executor.memory\", \"12G\") \\\n",
    "        .config(\"spark.executor.instances\", \"4\") \\\n",
    "        .config(\"spark.task.cpus\", \"1\") \\\n",
    "        .config(\"spark.task.resource.gpu.amount\", \"0.25\") \\\n",
    "        .config(\"spark.executor.resource.gpu.amount\", \"1\") \\\n",
    "        .config(\"spark.executor.resource.gpu.discoveryScript\", data_path+\"/getGpusResources.sh\") \\\n",
    "        .config(\"spark.driver.resource.gpu.amount\", \"1\") \\\n",
    "        .config(\"spark.driver.resource.gpu.discoveryScript\", data_path+\"/getGpusResources.sh\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = start_spark_session()\n",
    "sparknlp.start(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebf78cf-a084-4a50-85f7-a44084017dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset making...\n",
      "Finished getting dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting dataset making...\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"label\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "trainDataset = spark.read \\\n",
    "    .option(\"header\", False) \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"debugger_train.csv\")\n",
    "\n",
    "print(\"Finished getting dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69c51c9-774b-4aab-abe7-902e1c3d45e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDataset = trainDataset.withColumn(\"label\", when(trainDataset[\"label\"] == 2, 1).otherwise(0))\n",
    "# debugDataset = trainDataset.orderBy(rand()).limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c49a9e-27ca-41cb-9ccc-5cea910c8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules and classes\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import (\n",
    "    UniversalSentenceEncoder,\n",
    "    SentimentDLApproach\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30c45c-14de-440d-9991-97ab4d5956fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "useEmbeddings = UniversalSentenceEncoder.pretrained() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentdl = SentimentDLApproach() \\\n",
    "    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "    .setOutputCol(\"sentiment\") \\\n",
    "    .setLabelColumn(\"label\") \\\n",
    "    .setbatchSize(32) \\\n",
    "    .setlr(1e-3) \\\n",
    "    .setMaxEpochs(5) \\\n",
    "    .setEnableOutputLogs(True)\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "    .setStages(\n",
    "      [\n",
    "        documentAssembler,\n",
    "        useEmbeddings,\n",
    "        sentimentdl\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca509ea-8195-456c-baa1-9fa2b5742139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "pipelineModel = pipeline.fit(debugDataset)\n",
    "\n",
    "print(\"Model fitted.\")\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total time taken\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total execution time: {total_time} seconds\")\n",
    "\n",
    "# cat ~/annotator_logs/SentimentDLApproach_12faa854e3b3.log\n",
    "\n",
    "print(\"Starting logs.\")\n",
    "\n",
    "!cat ~/annotator_logs/SentimentDLApproach_12faa854e3b3.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717c8cc-94d4-43b0-ad8e-e37a5bf060d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
